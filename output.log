nohup: ignoring input
INFO:__main__:Current GPU: Tesla P40
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 199 examples [00:00, 24972.82 examples/s]
Map:   0%|          | 0/199 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 5870.49 examples/s]
Map:   0%|          | 0/189 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 189/189 [00:00<00:00, 3911.63 examples/s]
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 2078.24 examples/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

***** Running training *****
  Num examples = 189
  Num Epochs = 2
  Instantaneous batch size per device = 2
  Total train batch size (w. parallel, distributed & accumulation) = 2
  Gradient Accumulation steps = 1
  Total optimization steps = 190
  Number of trainable parameters = 1,235,814,400
  0%|          | 0/190 [00:00<?, ?it/s]  1%|          | 1/190 [00:00<03:01,  1.04it/s]  1%|          | 2/190 [00:01<02:37,  1.19it/s]  2%|â–         | 3/190 [00:02<02:31,  1.23it/s]  2%|â–         | 4/190 [00:03<02:28,  1.26it/s]  3%|â–Ž         | 5/190 [00:04<02:25,  1.27it/s]  3%|â–Ž         | 6/190 [00:04<02:24,  1.28it/s]  4%|â–Ž         | 7/190 [00:05<02:22,  1.28it/s]  4%|â–         | 8/190 [00:06<02:21,  1.28it/s]  5%|â–         | 9/190 [00:07<02:20,  1.29it/s]  5%|â–Œ         | 10/190 [00:07<02:19,  1.29it/s]  6%|â–Œ         | 11/190 [00:08<02:18,  1.29it/s]  6%|â–‹         | 12/190 [00:09<02:18,  1.29it/s]  7%|â–‹         | 13/190 [00:10<02:17,  1.29it/s]  7%|â–‹         | 14/190 [00:11<02:16,  1.29it/s]  8%|â–Š         | 15/190 [00:11<02:15,  1.29it/s]  8%|â–Š         | 16/190 [00:12<02:14,  1.29it/s]  9%|â–‰         | 17/190 [00:13<02:14,  1.29it/s]  9%|â–‰         | 18/190 [00:14<02:13,  1.29it/s] 10%|â–ˆ         | 19/190 [00:14<02:12,  1.29it/s] 11%|â–ˆ         | 20/190 [00:15<02:11,  1.29it/s] 11%|â–ˆ         | 21/190 [00:16<02:10,  1.29it/s] 12%|â–ˆâ–        | 22/190 [00:17<02:10,  1.29it/s] 12%|â–ˆâ–        | 23/190 [00:17<02:09,  1.29it/s] 13%|â–ˆâ–Ž        | 24/190 [00:18<02:08,  1.29it/s] 13%|â–ˆâ–Ž        | 25/190 [00:19<02:07,  1.29it/s] 14%|â–ˆâ–Ž        | 26/190 [00:20<02:07,  1.29it/s] 14%|â–ˆâ–        | 27/190 [00:21<02:06,  1.29it/s] 15%|â–ˆâ–        | 28/190 [00:21<02:05,  1.29it/s] 15%|â–ˆâ–Œ        | 29/190 [00:22<02:04,  1.29it/s] 16%|â–ˆâ–Œ        | 30/190 [00:23<02:04,  1.29it/s] 16%|â–ˆâ–‹        | 31/190 [00:24<02:03,  1.29it/s] 17%|â–ˆâ–‹        | 32/190 [00:24<02:02,  1.29it/s] 17%|â–ˆâ–‹        | 33/190 [00:25<02:01,  1.29it/s] 18%|â–ˆâ–Š        | 34/190 [00:26<02:00,  1.29it/s] 18%|â–ˆâ–Š        | 35/190 [00:27<02:00,  1.29it/s] 19%|â–ˆâ–‰        | 36/190 [00:28<01:59,  1.29it/s] 19%|â–ˆâ–‰        | 37/190 [00:28<01:58,  1.29it/s] 20%|â–ˆâ–ˆ        | 38/190 [00:29<01:57,  1.29it/s] 21%|â–ˆâ–ˆ        | 39/190 [00:30<01:57,  1.29it/s] 21%|â–ˆâ–ˆ        | 40/190 [00:31<01:56,  1.29it/s]                                                 21%|â–ˆâ–ˆ        | 40/190 [00:31<01:56,  1.29it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
{'loss': 1.5359, 'grad_norm': 22.697099685668945, 'learning_rate': 7.894736842105265e-06, 'epoch': 0.42}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 15.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.21it/s][A                                                
                                             [A 21%|â–ˆâ–ˆ        | 40/190 [00:31<01:56,  1.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.21it/s][A
                                             [A 22%|â–ˆâ–ˆâ–       | 41/190 [00:32<02:17,  1.08it/s] 22%|â–ˆâ–ˆâ–       | 42/190 [00:33<02:10,  1.14it/s] 23%|â–ˆâ–ˆâ–Ž       | 43/190 [00:33<02:04,  1.18it/s] 23%|â–ˆâ–ˆâ–Ž       | 44/190 [00:34<02:00,  1.21it/s] 24%|â–ˆâ–ˆâ–Ž       | 45/190 [00:35<01:57,  1.23it/s] 24%|â–ˆâ–ˆâ–       | 46/190 [00:36<01:55,  1.25it/s] 25%|â–ˆâ–ˆâ–       | 47/190 [00:37<01:53,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 48/190 [00:37<01:51,  1.27it/s] 26%|â–ˆâ–ˆâ–Œ       | 49/190 [00:38<01:50,  1.28it/s] 26%|â–ˆâ–ˆâ–‹       | 50/190 [00:39<01:49,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 51/190 [00:40<01:48,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 52/190 [00:40<01:47,  1.29it/s] 28%|â–ˆâ–ˆâ–Š       | 53/190 [00:41<01:46,  1.29it/s] 28%|â–ˆâ–ˆâ–Š       | 54/190 [00:42<01:45,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 55/190 [00:43<01:44,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 56/190 [00:44<01:43,  1.29it/s] 30%|â–ˆâ–ˆâ–ˆ       | 57/190 [00:44<01:43,  1.29it/s] 31%|â–ˆâ–ˆâ–ˆ       | 58/190 [00:45<01:42,  1.29it/s] 31%|â–ˆâ–ˆâ–ˆ       | 59/190 [00:46<01:41,  1.29it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 60/190 [00:47<01:40,  1.29it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 61/190 [00:47<01:40,  1.29it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 62/190 [00:48<01:39,  1.29it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 63/190 [00:49<01:38,  1.29it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 64/190 [00:50<01:37,  1.29it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 65/190 [00:51<01:36,  1.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 66/190 [00:51<01:36,  1.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 67/190 [00:52<01:35,  1.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 68/190 [00:53<01:34,  1.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 69/190 [00:54<01:33,  1.29it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 70/190 [00:54<01:33,  1.29it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 71/190 [00:55<01:32,  1.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 72/190 [00:56<01:31,  1.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 73/190 [00:57<01:30,  1.29it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 74/190 [00:58<01:29,  1.29it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 75/190 [00:58<01:29,  1.29it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 76/190 [00:59<01:28,  1.29it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 77/190 [01:00<01:27,  1.29it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 78/190 [01:01<01:26,  1.29it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 79/190 [01:01<01:26,  1.29it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 80/190 [01:02<01:25,  1.29it/s]                                                 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 80/190 [01:02<01:25,  1.29it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
{'eval_loss': 1.1551330089569092, 'eval_runtime': 0.4961, 'eval_samples_per_second': 20.155, 'eval_steps_per_second': 10.078, 'epoch': 0.42}
{'loss': 1.1041, 'grad_norm': 17.115909576416016, 'learning_rate': 5.789473684210527e-06, 'epoch': 0.84}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 15.11it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.12it/s][A                                                
                                             [A 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 80/190 [01:03<01:25,  1.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.12it/s][A
                                             [A 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 81/190 [01:03<01:40,  1.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 82/190 [01:04<01:35,  1.14it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 83/190 [01:05<01:30,  1.18it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/190 [01:06<01:27,  1.21it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/190 [01:07<01:25,  1.23it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 86/190 [01:07<01:23,  1.25it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 87/190 [01:08<01:21,  1.26it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 88/190 [01:09<01:20,  1.27it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 89/190 [01:10<01:19,  1.27it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 90/190 [01:10<01:18,  1.28it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 91/190 [01:11<01:17,  1.28it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 92/190 [01:12<01:16,  1.28it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 93/190 [01:13<01:15,  1.29it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 94/190 [01:14<01:14,  1.29it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 95/190 [01:14<01:10,  1.34it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 96/190 [01:15<01:10,  1.33it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 97/190 [01:16<01:10,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 98/190 [01:17<01:10,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 99/190 [01:17<01:09,  1.30it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 100/190 [01:18<01:09,  1.30it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 101/190 [01:19<01:08,  1.30it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 102/190 [01:20<01:08,  1.29it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/190 [01:20<01:07,  1.29it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/190 [01:21<01:06,  1.29it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 105/190 [01:22<01:05,  1.29it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 106/190 [01:23<01:05,  1.29it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 107/190 [01:24<01:04,  1.29it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 108/190 [01:24<01:03,  1.29it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 109/190 [01:25<01:02,  1.29it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 110/190 [01:26<01:02,  1.29it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 111/190 [01:27<01:01,  1.29it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 112/190 [01:27<01:00,  1.29it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 113/190 [01:28<00:59,  1.29it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 114/190 [01:29<00:58,  1.29it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 115/190 [01:30<00:58,  1.29it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 116/190 [01:30<00:57,  1.29it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 117/190 [01:31<00:56,  1.29it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 118/190 [01:32<00:55,  1.29it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 119/190 [01:33<00:55,  1.29it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 120/190 [01:34<00:54,  1.29it/s]                                                  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 120/190 [01:34<00:54,  1.29it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
{'eval_loss': 0.8453294634819031, 'eval_runtime': 0.4976, 'eval_samples_per_second': 20.096, 'eval_steps_per_second': 10.048, 'epoch': 0.84}
{'loss': 0.5641, 'grad_norm': 10.653029441833496, 'learning_rate': 3.6842105263157896e-06, 'epoch': 1.26}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 15.12it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.17it/s][A                                                 
                                             [A 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 120/190 [01:34<00:54,  1.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.17it/s][A
                                             [A 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 121/190 [01:35<01:03,  1.08it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122/190 [01:36<00:59,  1.14it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/190 [01:36<00:56,  1.18it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 124/190 [01:37<00:54,  1.21it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 125/190 [01:38<00:52,  1.23it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 126/190 [01:39<00:51,  1.25it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 127/190 [01:40<00:49,  1.26it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 128/190 [01:40<00:48,  1.27it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 129/190 [01:41<00:47,  1.28it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 130/190 [01:42<00:46,  1.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 131/190 [01:43<00:46,  1.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 132/190 [01:43<00:45,  1.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 133/190 [01:44<00:44,  1.29it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 134/190 [01:45<00:43,  1.29it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 135/190 [01:46<00:42,  1.29it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 136/190 [01:46<00:41,  1.29it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 137/190 [01:47<00:41,  1.29it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 138/190 [01:48<00:40,  1.29it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 139/190 [01:49<00:39,  1.29it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 140/190 [01:50<00:38,  1.29it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 141/190 [01:50<00:37,  1.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 142/190 [01:51<00:37,  1.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 143/190 [01:52<00:36,  1.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 144/190 [01:53<00:35,  1.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 145/190 [01:53<00:34,  1.29it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 146/190 [01:54<00:34,  1.29it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 147/190 [01:55<00:33,  1.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 148/190 [01:56<00:32,  1.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 149/190 [01:57<00:31,  1.29it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 150/190 [01:57<00:31,  1.29it/s]Saving model checkpoint to ./fine-tuned-model/checkpoint-150
Configuration saved in ./fine-tuned-model/checkpoint-150/config.json
Configuration saved in ./fine-tuned-model/checkpoint-150/generation_config.json
Model weights saved in ./fine-tuned-model/checkpoint-150/model.safetensors
tokenizer config file saved in ./fine-tuned-model/checkpoint-150/tokenizer_config.json
Special tokens file saved in ./fine-tuned-model/checkpoint-150/special_tokens_map.json
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 151/190 [02:11<02:57,  4.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 152/190 [02:11<02:09,  3.42s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 153/190 [02:12<01:37,  2.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 154/190 [02:13<01:14,  2.07s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 155/190 [02:14<00:58,  1.68s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 156/190 [02:15<00:47,  1.41s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 157/190 [02:15<00:40,  1.22s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 158/190 [02:16<00:34,  1.09s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 159/190 [02:17<00:30,  1.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160/190 [02:18<00:27,  1.08it/s]                                                  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160/190 [02:18<00:27,  1.08it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
{'eval_loss': 0.9280869364738464, 'eval_runtime': 0.497, 'eval_samples_per_second': 20.12, 'eval_steps_per_second': 10.06, 'epoch': 1.26}
{'loss': 0.3915, 'grad_norm': 10.350464820861816, 'learning_rate': 1.5789473684210526e-06, 'epoch': 1.68}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 15.14it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.16it/s][A                                                 
                                             [A 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160/190 [02:18<00:27,  1.08it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.16it/s][A
                                             [A 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 161/190 [02:19<00:29,  1.03s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 162/190 [02:20<00:26,  1.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 163/190 [02:21<00:24,  1.11it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 164/190 [02:21<00:22,  1.16it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 165/190 [02:22<00:20,  1.19it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 166/190 [02:23<00:19,  1.22it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 167/190 [02:24<00:18,  1.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 168/190 [02:24<00:17,  1.26it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 169/190 [02:25<00:16,  1.27it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 170/190 [02:26<00:15,  1.27it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 171/190 [02:27<00:14,  1.28it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 172/190 [02:28<00:14,  1.28it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 173/190 [02:28<00:13,  1.28it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 174/190 [02:29<00:12,  1.29it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 175/190 [02:30<00:11,  1.29it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 176/190 [02:31<00:10,  1.29it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 177/190 [02:31<00:10,  1.29it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 178/190 [02:32<00:09,  1.29it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 179/190 [02:33<00:08,  1.29it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 180/190 [02:34<00:07,  1.29it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 181/190 [02:34<00:06,  1.29it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 182/190 [02:35<00:06,  1.29it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 183/190 [02:36<00:05,  1.29it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 184/190 [02:37<00:04,  1.29it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 185/190 [02:38<00:03,  1.29it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 186/190 [02:38<00:03,  1.29it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 187/190 [02:39<00:02,  1.29it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 188/190 [02:40<00:01,  1.29it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 189/190 [02:41<00:00,  1.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [02:41<00:00,  1.35it/s]Saving model checkpoint to ./fine-tuned-model/checkpoint-190
Configuration saved in ./fine-tuned-model/checkpoint-190/config.json
Configuration saved in ./fine-tuned-model/checkpoint-190/generation_config.json
Model weights saved in ./fine-tuned-model/checkpoint-190/model.safetensors
tokenizer config file saved in ./fine-tuned-model/checkpoint-190/tokenizer_config.json
Special tokens file saved in ./fine-tuned-model/checkpoint-190/special_tokens_map.json


Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [02:54<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [02:54<00:00,  1.09it/s]
Saving model checkpoint to ./fine-tuned-model
Configuration saved in ./fine-tuned-model/config.json
Configuration saved in ./fine-tuned-model/generation_config.json
Model weights saved in ./fine-tuned-model/model.safetensors
tokenizer config file saved in ./fine-tuned-model/tokenizer_config.json
Special tokens file saved in ./fine-tuned-model/special_tokens_map.json
tokenizer config file saved in ./fine-tuned-model/tokenizer_config.json
Special tokens file saved in ./fine-tuned-model/special_tokens_map.json
INFO:__main__:Model and tokenizer saved to ./fine-tuned-model
{'eval_loss': 0.8823511004447937, 'eval_runtime': 0.4975, 'eval_samples_per_second': 20.101, 'eval_steps_per_second': 10.05, 'epoch': 1.68}
{'train_runtime': 174.746, 'train_samples_per_second': 2.163, 'train_steps_per_second': 1.087, 'train_loss': 0.8143609900223582, 'epoch': 2.0}
