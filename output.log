nohup: ignoring input
INFO:__main__:Current GPU: Tesla P40
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ERROR:bitsandbytes.cextension:Could not load bitsandbytes native library: libcusparse.so.11: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/loc/miniconda3/envs/py38/lib/python3.8/site-packages/bitsandbytes/cextension.py", line 104, in <module>
    lib = get_native_library()
  File "/home/loc/miniconda3/envs/py38/lib/python3.8/site-packages/bitsandbytes/cextension.py", line 91, in get_native_library
    dll = ct.cdll.LoadLibrary(str(binary_path))
  File "/home/loc/miniconda3/envs/py38/lib/python3.8/ctypes/__init__.py", line 451, in LoadLibrary
    return self._dlltype(name)
  File "/home/loc/miniconda3/envs/py38/lib/python3.8/ctypes/__init__.py", line 373, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: libcusparse.so.11: cannot open shared object file: No such file or directory
WARNING:bitsandbytes.cextension:
CUDA Setup failed despite CUDA being available. Please run the following command to get more information:

python -m bitsandbytes

Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues

INFO:__main__:LoRA adaptation applied to model.
Map:   0%|          | 0/189 [00:00<?, ? examples/s]Map: 100%|██████████| 189/189 [00:00<00:00, 4229.10 examples/s]
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 2115.45 examples/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

***** Running training *****
  Num examples = 189
  Num Epochs = 2
  Instantaneous batch size per device = 2
  Total train batch size (w. parallel, distributed & accumulation) = 2
  Gradient Accumulation steps = 1
  Total optimization steps = 190
  Number of trainable parameters = 1,703,936
  0%|          | 0/190 [00:00<?, ?it/s]  1%|          | 1/190 [00:00<00:57,  3.27it/s]  1%|          | 2/190 [00:00<00:46,  4.01it/s]  2%|▏         | 3/190 [00:00<00:43,  4.32it/s]  2%|▏         | 4/190 [00:00<00:41,  4.49it/s]  3%|▎         | 5/190 [00:01<00:40,  4.58it/s]  3%|▎         | 6/190 [00:01<00:39,  4.64it/s]  4%|▎         | 7/190 [00:01<00:39,  4.68it/s]  4%|▍         | 8/190 [00:01<00:38,  4.70it/s]  5%|▍         | 9/190 [00:01<00:38,  4.72it/s]  5%|▌         | 10/190 [00:02<00:38,  4.73it/s]  6%|▌         | 11/190 [00:02<00:37,  4.74it/s]  6%|▋         | 12/190 [00:02<00:37,  4.75it/s]  7%|▋         | 13/190 [00:02<00:37,  4.75it/s]  7%|▋         | 14/190 [00:03<00:37,  4.75it/s]  8%|▊         | 15/190 [00:03<00:36,  4.75it/s]  8%|▊         | 16/190 [00:03<00:36,  4.76it/s]  9%|▉         | 17/190 [00:03<00:36,  4.76it/s]  9%|▉         | 18/190 [00:03<00:36,  4.76it/s] 10%|█         | 19/190 [00:04<00:35,  4.76it/s] 11%|█         | 20/190 [00:04<00:35,  4.76it/s] 11%|█         | 21/190 [00:04<00:35,  4.75it/s] 12%|█▏        | 22/190 [00:04<00:35,  4.75it/s] 12%|█▏        | 23/190 [00:04<00:35,  4.75it/s] 13%|█▎        | 24/190 [00:05<00:34,  4.75it/s] 13%|█▎        | 25/190 [00:05<00:34,  4.75it/s] 14%|█▎        | 26/190 [00:05<00:34,  4.74it/s] 14%|█▍        | 27/190 [00:05<00:34,  4.74it/s] 15%|█▍        | 28/190 [00:05<00:34,  4.74it/s] 15%|█▌        | 29/190 [00:06<00:33,  4.75it/s] 16%|█▌        | 30/190 [00:06<00:33,  4.75it/s] 16%|█▋        | 31/190 [00:06<00:33,  4.75it/s] 17%|█▋        | 32/190 [00:06<00:33,  4.75it/s] 17%|█▋        | 33/190 [00:07<00:33,  4.75it/s] 18%|█▊        | 34/190 [00:07<00:32,  4.74it/s] 18%|█▊        | 35/190 [00:07<00:32,  4.75it/s] 19%|█▉        | 36/190 [00:07<00:32,  4.75it/s] 19%|█▉        | 37/190 [00:07<00:32,  4.75it/s] 20%|██        | 38/190 [00:08<00:32,  4.74it/s] 21%|██        | 39/190 [00:08<00:31,  4.75it/s] 21%|██        | 40/190 [00:08<00:31,  4.75it/s]                                                 21%|██        | 40/190 [00:08<00:31,  4.75it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
{'loss': 4.528, 'grad_norm': 5.663399696350098, 'learning_rate': 7.894736842105265e-06, 'epoch': 0.42}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 19.72it/s][A
 80%|████████  | 4/5 [00:00<00:00, 12.41it/s][A                                                
                                             [A 21%|██        | 40/190 [00:09<00:31,  4.75it/s]
100%|██████████| 5/5 [00:00<00:00, 12.41it/s][A
                                             [A 22%|██▏       | 41/190 [00:09<00:54,  2.75it/s] 22%|██▏       | 42/190 [00:09<00:47,  3.15it/s] 23%|██▎       | 43/190 [00:09<00:41,  3.50it/s] 23%|██▎       | 44/190 [00:09<00:38,  3.80it/s] 24%|██▎       | 45/190 [00:10<00:35,  4.03it/s] 24%|██▍       | 46/190 [00:10<00:34,  4.22it/s] 25%|██▍       | 47/190 [00:10<00:32,  4.37it/s] 25%|██▌       | 48/190 [00:10<00:31,  4.48it/s] 26%|██▌       | 49/190 [00:10<00:30,  4.55it/s] 26%|██▋       | 50/190 [00:11<00:30,  4.61it/s] 27%|██▋       | 51/190 [00:11<00:29,  4.65it/s] 27%|██▋       | 52/190 [00:11<00:29,  4.68it/s] 28%|██▊       | 53/190 [00:11<00:29,  4.70it/s] 28%|██▊       | 54/190 [00:11<00:28,  4.72it/s] 29%|██▉       | 55/190 [00:12<00:28,  4.72it/s] 29%|██▉       | 56/190 [00:12<00:28,  4.73it/s] 30%|███       | 57/190 [00:12<00:28,  4.74it/s] 31%|███       | 58/190 [00:12<00:27,  4.74it/s] 31%|███       | 59/190 [00:13<00:27,  4.74it/s] 32%|███▏      | 60/190 [00:13<00:27,  4.75it/s] 32%|███▏      | 61/190 [00:13<00:27,  4.75it/s] 33%|███▎      | 62/190 [00:13<00:26,  4.75it/s] 33%|███▎      | 63/190 [00:13<00:26,  4.75it/s] 34%|███▎      | 64/190 [00:14<00:26,  4.75it/s] 34%|███▍      | 65/190 [00:14<00:26,  4.75it/s] 35%|███▍      | 66/190 [00:14<00:26,  4.75it/s] 35%|███▌      | 67/190 [00:14<00:25,  4.75it/s] 36%|███▌      | 68/190 [00:14<00:25,  4.75it/s] 36%|███▋      | 69/190 [00:15<00:25,  4.75it/s] 37%|███▋      | 70/190 [00:15<00:25,  4.75it/s] 37%|███▋      | 71/190 [00:15<00:25,  4.75it/s] 38%|███▊      | 72/190 [00:15<00:24,  4.75it/s] 38%|███▊      | 73/190 [00:15<00:24,  4.75it/s] 39%|███▉      | 74/190 [00:16<00:24,  4.75it/s] 39%|███▉      | 75/190 [00:16<00:24,  4.75it/s] 40%|████      | 76/190 [00:16<00:24,  4.75it/s] 41%|████      | 77/190 [00:16<00:23,  4.75it/s] 41%|████      | 78/190 [00:17<00:23,  4.75it/s] 42%|████▏     | 79/190 [00:17<00:23,  4.75it/s] 42%|████▏     | 80/190 [00:17<00:23,  4.75it/s]                                                 42%|████▏     | 80/190 [00:17<00:23,  4.75it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
{'eval_loss': 4.182150363922119, 'eval_runtime': 0.5092, 'eval_samples_per_second': 19.637, 'eval_steps_per_second': 9.819, 'epoch': 0.42}
{'loss': 3.7775, 'grad_norm': 5.008531093597412, 'learning_rate': 5.789473684210527e-06, 'epoch': 0.84}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 19.69it/s][A
 80%|████████  | 4/5 [00:00<00:00, 12.37it/s][A                                                
                                             [A 42%|████▏     | 80/190 [00:17<00:23,  4.75it/s]
100%|██████████| 5/5 [00:00<00:00, 12.37it/s][A
                                             [A 43%|████▎     | 81/190 [00:18<00:39,  2.74it/s] 43%|████▎     | 82/190 [00:18<00:34,  3.14it/s] 44%|████▎     | 83/190 [00:18<00:30,  3.50it/s] 44%|████▍     | 84/190 [00:18<00:27,  3.80it/s] 45%|████▍     | 85/190 [00:19<00:25,  4.04it/s] 45%|████▌     | 86/190 [00:19<00:24,  4.23it/s] 46%|████▌     | 87/190 [00:19<00:23,  4.37it/s] 46%|████▋     | 88/190 [00:19<00:22,  4.48it/s] 47%|████▋     | 89/190 [00:19<00:22,  4.56it/s] 47%|████▋     | 90/190 [00:20<00:21,  4.62it/s] 48%|████▊     | 91/190 [00:20<00:21,  4.66it/s] 48%|████▊     | 92/190 [00:20<00:20,  4.68it/s] 49%|████▉     | 93/190 [00:20<00:20,  4.70it/s] 49%|████▉     | 94/190 [00:20<00:20,  4.71it/s] 50%|█████     | 95/190 [00:21<00:17,  5.30it/s] 51%|█████     | 96/190 [00:21<00:18,  5.12it/s] 51%|█████     | 97/190 [00:21<00:18,  5.00it/s] 52%|█████▏    | 98/190 [00:21<00:18,  4.93it/s] 52%|█████▏    | 99/190 [00:21<00:18,  4.87it/s] 53%|█████▎    | 100/190 [00:22<00:18,  4.83it/s] 53%|█████▎    | 101/190 [00:22<00:18,  4.80it/s] 54%|█████▎    | 102/190 [00:22<00:18,  4.79it/s] 54%|█████▍    | 103/190 [00:22<00:18,  4.78it/s] 55%|█████▍    | 104/190 [00:22<00:18,  4.77it/s] 55%|█████▌    | 105/190 [00:23<00:17,  4.77it/s] 56%|█████▌    | 106/190 [00:23<00:17,  4.76it/s] 56%|█████▋    | 107/190 [00:23<00:17,  4.76it/s] 57%|█████▋    | 108/190 [00:23<00:17,  4.76it/s] 57%|█████▋    | 109/190 [00:23<00:17,  4.76it/s] 58%|█████▊    | 110/190 [00:24<00:16,  4.76it/s] 58%|█████▊    | 111/190 [00:24<00:16,  4.76it/s] 59%|█████▉    | 112/190 [00:24<00:16,  4.75it/s] 59%|█████▉    | 113/190 [00:24<00:16,  4.75it/s] 60%|██████    | 114/190 [00:25<00:15,  4.75it/s] 61%|██████    | 115/190 [00:25<00:15,  4.74it/s] 61%|██████    | 116/190 [00:25<00:15,  4.74it/s] 62%|██████▏   | 117/190 [00:25<00:15,  4.75it/s] 62%|██████▏   | 118/190 [00:25<00:15,  4.75it/s] 63%|██████▎   | 119/190 [00:26<00:14,  4.75it/s] 63%|██████▎   | 120/190 [00:26<00:14,  4.75it/s]                                                  63%|██████▎   | 120/190 [00:26<00:14,  4.75it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
{'eval_loss': 3.5890591144561768, 'eval_runtime': 0.5106, 'eval_samples_per_second': 19.585, 'eval_steps_per_second': 9.792, 'epoch': 0.84}
{'loss': 3.3455, 'grad_norm': 6.311323165893555, 'learning_rate': 3.6842105263157896e-06, 'epoch': 1.26}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 19.72it/s][A
 80%|████████  | 4/5 [00:00<00:00, 12.40it/s][A                                                 
                                             [A 63%|██████▎   | 120/190 [00:26<00:14,  4.75it/s]
100%|██████████| 5/5 [00:00<00:00, 12.40it/s][A
                                             [A 64%|██████▎   | 121/190 [00:27<00:25,  2.75it/s] 64%|██████▍   | 122/190 [00:27<00:21,  3.15it/s] 65%|██████▍   | 123/190 [00:27<00:19,  3.50it/s] 65%|██████▌   | 124/190 [00:27<00:17,  3.80it/s] 66%|██████▌   | 125/190 [00:27<00:16,  4.04it/s] 66%|██████▋   | 126/190 [00:28<00:15,  4.23it/s] 67%|██████▋   | 127/190 [00:28<00:14,  4.38it/s] 67%|██████▋   | 128/190 [00:28<00:13,  4.48it/s] 68%|██████▊   | 129/190 [00:28<00:13,  4.56it/s] 68%|██████▊   | 130/190 [00:28<00:12,  4.62it/s] 69%|██████▉   | 131/190 [00:29<00:12,  4.66it/s] 69%|██████▉   | 132/190 [00:29<00:12,  4.69it/s] 70%|███████   | 133/190 [00:29<00:12,  4.71it/s] 71%|███████   | 134/190 [00:29<00:11,  4.72it/s] 71%|███████   | 135/190 [00:29<00:11,  4.73it/s] 72%|███████▏  | 136/190 [00:30<00:11,  4.74it/s] 72%|███████▏  | 137/190 [00:30<00:11,  4.74it/s] 73%|███████▎  | 138/190 [00:30<00:10,  4.74it/s] 73%|███████▎  | 139/190 [00:30<00:10,  4.75it/s] 74%|███████▎  | 140/190 [00:31<00:10,  4.75it/s] 74%|███████▍  | 141/190 [00:31<00:10,  4.75it/s] 75%|███████▍  | 142/190 [00:31<00:10,  4.75it/s] 75%|███████▌  | 143/190 [00:31<00:09,  4.75it/s] 76%|███████▌  | 144/190 [00:31<00:09,  4.75it/s] 76%|███████▋  | 145/190 [00:32<00:09,  4.75it/s] 77%|███████▋  | 146/190 [00:32<00:09,  4.75it/s] 77%|███████▋  | 147/190 [00:32<00:09,  4.75it/s] 78%|███████▊  | 148/190 [00:32<00:08,  4.75it/s] 78%|███████▊  | 149/190 [00:32<00:08,  4.75it/s] 79%|███████▉  | 150/190 [00:33<00:08,  4.75it/s]Saving model checkpoint to logs/checkpoint-150
loading configuration file config.json from cache at /home/loc/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 16,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 32.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.44.2",
  "use_cache": true,
  "vocab_size": 128256
}

tokenizer config file saved in logs/checkpoint-150/tokenizer_config.json
Special tokens file saved in logs/checkpoint-150/special_tokens_map.json
 79%|███████▉  | 151/190 [00:34<00:21,  1.85it/s] 80%|████████  | 152/190 [00:34<00:16,  2.27it/s] 81%|████████  | 153/190 [00:34<00:13,  2.69it/s] 81%|████████  | 154/190 [00:35<00:11,  3.09it/s] 82%|████████▏ | 155/190 [00:35<00:10,  3.45it/s] 82%|████████▏ | 156/190 [00:35<00:09,  3.76it/s] 83%|████████▎ | 157/190 [00:35<00:08,  4.01it/s] 83%|████████▎ | 158/190 [00:35<00:07,  4.21it/s] 84%|████████▎ | 159/190 [00:36<00:07,  4.36it/s] 84%|████████▍ | 160/190 [00:36<00:06,  4.47it/s]                                                  84%|████████▍ | 160/190 [00:36<00:06,  4.47it/s]
***** Running Evaluation *****
  Num examples = 10
  Batch size = 2
{'eval_loss': 3.186678886413574, 'eval_runtime': 0.5095, 'eval_samples_per_second': 19.626, 'eval_steps_per_second': 9.813, 'epoch': 1.26}
{'loss': 2.9714, 'grad_norm': 5.149895668029785, 'learning_rate': 1.5789473684210526e-06, 'epoch': 1.68}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 19.67it/s][A
 80%|████████  | 4/5 [00:00<00:00, 12.40it/s][A                                                 
                                             [A 84%|████████▍ | 160/190 [00:36<00:06,  4.47it/s]
100%|██████████| 5/5 [00:00<00:00, 12.40it/s][A
                                             [A 85%|████████▍ | 161/190 [00:37<00:10,  2.67it/s] 85%|████████▌ | 162/190 [00:37<00:09,  3.07it/s] 86%|████████▌ | 163/190 [00:37<00:07,  3.44it/s] 86%|████████▋ | 164/190 [00:37<00:06,  3.75it/s] 87%|████████▋ | 165/190 [00:37<00:06,  4.00it/s] 87%|████████▋ | 166/190 [00:38<00:05,  4.20it/s] 88%|████████▊ | 167/190 [00:38<00:05,  4.35it/s] 88%|████████▊ | 168/190 [00:38<00:04,  4.47it/s] 89%|████████▉ | 169/190 [00:38<00:04,  4.55it/s] 89%|████████▉ | 170/190 [00:38<00:04,  4.61it/s] 90%|█████████ | 171/190 [00:39<00:04,  4.65it/s] 91%|█████████ | 172/190 [00:39<00:03,  4.68it/s] 91%|█████████ | 173/190 [00:39<00:03,  4.70it/s] 92%|█████████▏| 174/190 [00:39<00:03,  4.72it/s] 92%|█████████▏| 175/190 [00:40<00:03,  4.73it/s] 93%|█████████▎| 176/190 [00:40<00:02,  4.74it/s] 93%|█████████▎| 177/190 [00:40<00:02,  4.74it/s] 94%|█████████▎| 178/190 [00:40<00:02,  4.74it/s] 94%|█████████▍| 179/190 [00:40<00:02,  4.74it/s] 95%|█████████▍| 180/190 [00:41<00:02,  4.74it/s] 95%|█████████▌| 181/190 [00:41<00:01,  4.75it/s] 96%|█████████▌| 182/190 [00:41<00:01,  4.74it/s] 96%|█████████▋| 183/190 [00:41<00:01,  4.74it/s] 97%|█████████▋| 184/190 [00:41<00:01,  4.74it/s] 97%|█████████▋| 185/190 [00:42<00:01,  4.74it/s] 98%|█████████▊| 186/190 [00:42<00:00,  4.74it/s] 98%|█████████▊| 187/190 [00:42<00:00,  4.74it/s] 99%|█████████▉| 188/190 [00:42<00:00,  4.75it/s] 99%|█████████▉| 189/190 [00:42<00:00,  4.75it/s]100%|██████████| 190/190 [00:43<00:00,  5.33it/s]Saving model checkpoint to logs/checkpoint-190
loading configuration file config.json from cache at /home/loc/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 16,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 32.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.44.2",
  "use_cache": true,
  "vocab_size": 128256
}

tokenizer config file saved in logs/checkpoint-190/tokenizer_config.json
Special tokens file saved in logs/checkpoint-190/special_tokens_map.json


Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 190/190 [00:43<00:00,  5.33it/s]100%|██████████| 190/190 [00:43<00:00,  4.35it/s]
Saving model checkpoint to logs
loading configuration file config.json from cache at /home/loc/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 16,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 32.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.44.2",
  "use_cache": true,
  "vocab_size": 128256
}

tokenizer config file saved in logs/tokenizer_config.json
Special tokens file saved in logs/special_tokens_map.json
tokenizer config file saved in logs/tokenizer_config.json
Special tokens file saved in logs/special_tokens_map.json
INFO:__main__:Model and tokenizer saved to logs
{'eval_loss': 2.932422161102295, 'eval_runtime': 0.51, 'eval_samples_per_second': 19.61, 'eval_steps_per_second': 9.805, 'epoch': 1.68}
{'train_runtime': 43.7126, 'train_samples_per_second': 8.647, 'train_steps_per_second': 4.347, 'train_loss': 3.5231827585320725, 'epoch': 2.0}
